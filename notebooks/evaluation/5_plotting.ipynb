{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "15ad0c0c-a618-4f8c-80c4-47af2f0d21bf",
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "import pandas as pd\n",
                "import seaborn as sns\n",
                "from conformal_data_cleaning.evaluation.utils import normalize_improvement, normalize_performance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5a1d0609-8b36-437f-a5e4-f7e631ea0c0b",
            "metadata": {},
            "outputs": [],
            "source": [
                "processed_path = Path(\"../../processed\")\n",
                "results_file = processed_path / \"final-experiments\" / \"results_cache.csv\"\n",
                "dataset_descriptions_file = Path(\"../../data/dataset_descriptions.csv\")\n",
                "figures_path = Path(\"../../plots\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.rcParams[\"pdf.fonttype\"] = 42\n",
                "\n",
                "sns.set(\n",
                "    style=\"whitegrid\",\n",
                ")\n",
                "sns.set_context(\"paper\", font_scale=1.5)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Garf failed those datasets because of wrong dtypes: 4135, 251, 1200, 218, 1046"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset_descriptions = pd.read_csv(dataset_descriptions_file).convert_dtypes().set_index(\"task_id\")\n",
                "tabular_task_id = dataset_descriptions[dataset_descriptions[\"tabular\"]].index\n",
                "\n",
                "results = (\n",
                "    pd.concat(\n",
                "        [\n",
                "            pd.read_csv(results_file)\n",
                "            .convert_dtypes()\n",
                "            .query(\"cleaner_type == 'ConformalAutoGluon'\")\n",
                "            .copy()\n",
                "            .drop(columns=\"cleaner_type\")\n",
                "            .rename(columns={\"confidence_level\": \"hyperparameter\"})\n",
                "            .assign(method=\"CDC (ours)\"),\n",
                "            pd.read_csv(results_file)\n",
                "            .convert_dtypes()\n",
                "            .query(\"cleaner_type == 'Garf'\")\n",
                "            .copy()\n",
                "            .drop(columns=\"cleaner_type\")\n",
                "            .rename(columns={\"confidence_level\": \"hyperparameter\"})\n",
                "            .assign(method=\"Garf\")\n",
                "            .assign(hyperparameter=0.5),\n",
                "            pd.read_csv(results_file)\n",
                "            .convert_dtypes()\n",
                "            .query(\"cleaner_type == 'AutoGluon'\")\n",
                "            .copy()\n",
                "            .drop(columns=\"cleaner_type\")\n",
                "            .rename(columns={\"confidence_level\": \"hyperparameter\"})\n",
                "            .assign(method=\"ML\"),\n",
                "        ],\n",
                "        axis=0,\n",
                "        ignore_index=True,\n",
                "    )\n",
                "    .assign(\n",
                "        error_bins=lambda df: pd.cut(\n",
                "            df[\"actual_error_fraction\"], [x / 10 for x in range(6)], include_lowest=True,\n",
                "        ).astype(str),\n",
                "        method=lambda df: df[\"method\"].astype(\"category\"),\n",
                "        hyperparameter=lambda df: df[\"hyperparameter\"].astype(\"category\"),\n",
                "        method_hyperparameter=lambda df: df[\"method\"].astype(str) + \", \" + df[\"hyperparameter\"].astype(str),\n",
                "        error_detection_fraction__mean=lambda df: df[\"error_detection_fraction__mean\"],\n",
                "    )\n",
                "    .pipe(lambda df: df.join(df.groupby(\"task_id\").apply(normalize_performance)))\n",
                "    .pipe(lambda df: df.join(df.groupby(\"task_id\").apply(normalize_improvement)))\n",
                ")\n",
                "\n",
                "rel_set_size_quantiles = dict()\n",
                "for q in [0.2, 0.8]:\n",
                "    rel_set_size_quantiles[q] = {\n",
                "        value[\"hyperparameter\"]: value[\"relative_average_set_size__mean\"]\n",
                "        for _, value in (\n",
                "            results.groupby([\"hyperparameter\"])[[\"relative_average_set_size__mean\"]]\n",
                "            .agg(lambda x: x.quantile(q))\n",
                "            .reset_index()\n",
                "            .to_dict(\"index\")\n",
                "            .items()\n",
                "        )\n",
                "    }\n",
                "\n",
                "results = results.assign(\n",
                "    set_size_groups=lambda df: [\n",
                "        rel_set_size\n",
                "        if pd.isna(rel_set_size)\n",
                "        else \"top\"  # if NAN\n",
                "        if rel_set_size < rel_set_size_quantiles[0.2][hyperparameter]\n",
                "        else \"middle\"\n",
                "        if rel_set_size < rel_set_size_quantiles[0.8][hyperparameter]\n",
                "        else \"worst\"\n",
                "        for rel_set_size, hyperparameter in df[[\"relative_average_set_size__mean\", \"hyperparameter\"]].values\n",
                "    ],\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "id_columns = [\"task_id\", \"error_type\", \"error_fraction\", \"actual_error_fraction\"]"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Dataset Statistics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "error_statistics = pd.read_csv(\"../../data/corrupted/error_statistics.csv\")\n",
                "error_statistics.describe()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Outlier Detection TPR vs. FPR"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "id_columns = [\"error_bins\"]\n",
                "metric_columns = [\"error_detection_fraction__mean\", \"error_wrong_detection_fraction__mean\"]\n",
                "\n",
                "data = (\n",
                "    results.groupby(id_columns + [\"hyperparameter\", \"method\"])[metric_columns]\n",
                "    .mean()\n",
                "    .reset_index()\n",
                "    .melt(\n",
                "        id_vars=id_columns + [\"method\", \"hyperparameter\"],\n",
                "        value_vars=metric_columns,\n",
                "    )\n",
                "    .assign(\n",
                "        variable=lambda df: df[\"variable\"].astype(\"category\"),\n",
                "    )\n",
                "    .replace(\n",
                "        {\n",
                "            \"error_detection_fraction__mean\": \"Outlier Detection TPR\",\n",
                "            \"error_wrong_detection_fraction__mean\": \"Outlier Detection FPR\",\n",
                "        },\n",
                "    )\n",
                "    .rename(columns={\"hyperparameter\": \"Hyperparameter\", \"method\": \"Method\", \"value\": \"mean\"})\n",
                ")\n",
                "\n",
                "\n",
                "plot: sns.FacetGrid = sns.relplot(\n",
                "    x=\"error_bins\",\n",
                "    y=\"mean\",\n",
                "    hue=\"Hyperparameter\",\n",
                "    style=\"Method\",\n",
                "    col=\"variable\",\n",
                "    kind=\"line\",\n",
                "    data=data.dropna(),\n",
                ")\n",
                "\n",
                "\n",
                "plot.figure.axes[0].set_ylim((0, 1))\n",
                "plot.figure.axes[1].set_ylim((0, 1))\n",
                "\n",
                "plot.set_xticklabels([\"[0-10]\", \"(10-20]\", \"(20-30]\", \"(30-40]\", \"(40-50]\"])\n",
                "plot.set_xlabels(r\"Error Fraction ($\\%$)\")\n",
                "plot.set_ylabels(\"\")\n",
                "plot.set_titles(col_template=\"{col_name}\")\n",
                "\n",
                "plot.tight_layout()\n",
                "plot.savefig(figures_path / \"outlier_detection_TPR_vs_FPR_plot.pdf\", bbox_inches=\"tight\")\n",
                "plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Cleaning Performance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "id_columns = [\"error_bins\"]\n",
                "metric_columns = [\n",
                "    \"cleaned_performance__mean_normalized\",\n",
                "    \"improvement_in_percent__mean_normalized\",\n",
                "    \"cleaned_performance__mean\",\n",
                "    \"improvement_in_percent__mean\",\n",
                "]\n",
                "\n",
                "plot = sns.relplot(\n",
                "    x=\"error_bins\",\n",
                "    y=\"improvement_in_percent__mean\",\n",
                "    hue=\"Hyperparameter\",\n",
                "    style=\"Method\",\n",
                "    kind=\"line\",\n",
                "    facet_kws={\"sharey\": False, \"sharex\": False},\n",
                "    data=(\n",
                "        results.groupby(id_columns + [\"hyperparameter\", \"method\"])[metric_columns]\n",
                "        .median()\n",
                "        .reset_index()\n",
                "        .rename(columns={\"hyperparameter\": \"Hyperparameter\", \"method\": \"Method\"})\n",
                "        .dropna()\n",
                "    ),\n",
                ")\n",
                "\n",
                "plot.set_xticklabels([\"[0-10]\", \"(10-20]\", \"(20-30]\", \"(30-40]\", \"(40-50]\"])\n",
                "plot.set_xlabels(r\"Error Fraction ($\\%$)\")\n",
                "plot.set_ylabels(r\"Downstream Improvement ($\\%$)\")\n",
                "\n",
                "\n",
                "plot.tight_layout()\n",
                "plot.savefig(figures_path / \"performance_improvement_plot.pdf\", bbox_inches=\"tight\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot = sns.catplot(\n",
                "    x=\"error_bins\",\n",
                "    y=\"improvement_in_percent__mean\",\n",
                "    hue=\"Hyperparameter\",\n",
                "    col=\"Method\",\n",
                "    kind=\"box\",\n",
                "    data=(\n",
                "        results.query('method != \"Garf\"')\n",
                "        .assign(\n",
                "            method=lambda df: df[\"method\"].cat.remove_unused_categories(),\n",
                "        )\n",
                "        .rename(columns={\"hyperparameter\": \"Hyperparameter\", \"method\": \"Method\"})\n",
                "    ),\n",
                ")\n",
                "\n",
                "plot.set(ylim=(-100, 100))\n",
                "plot.set_xticklabels([\"[0-10]\", \"(10-20]\", \"(20-30]\", \"(30-40]\", \"(40-50]\"])\n",
                "plot.set_xlabels(r\"Error Fraction ($\\%$)\")\n",
                "plot.set_ylabels(r\"Downstream Improvement ($\\%$)\")\n",
                "\n",
                "\n",
                "plot.tight_layout()\n",
                "plot.savefig(figures_path / \"performance_improvement_box_plot.pdf\", bbox_inches=\"tight\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "id_columns = [\"error_bins\"]\n",
                "metric_columns = [\"improvement_in_percent__mean\"]\n",
                "\n",
                "plot = sns.relplot(\n",
                "    x=\"error_bins\",\n",
                "    y=\"improvement_in_percent__mean\",\n",
                "    hue=\"Hyperparameter\",\n",
                "    col=\"set_size_groups\",\n",
                "    col_order=[\n",
                "        r\"$20\\%$ Easiest Experiments\",\n",
                "        r\"$20 - 80\\%$ Moderately Difficult Experiments\",\n",
                "        r\"$20\\%$ Difficult Experiments\",\n",
                "    ],\n",
                "    kind=\"line\",\n",
                "    facet_kws={\"sharey\": False, \"sharex\": False},\n",
                "    data=(\n",
                "        results.groupby(id_columns + [\"hyperparameter\", \"method\", \"set_size_groups\"])[metric_columns]\n",
                "        .median()\n",
                "        .reset_index()\n",
                "        .rename(columns={\"hyperparameter\": \"Hyperparameter\", \"method\": \"Method\"})\n",
                "        .replace(\n",
                "            {\n",
                "                \"top\": r\"$20\\%$ Easiest Experiments\",\n",
                "                \"middle\": r\"$20 - 80\\%$ Moderately Difficult Experiments\",\n",
                "                \"worst\": r\"$20\\%$ Difficult Experiments\",\n",
                "            },\n",
                "        )\n",
                "        .dropna()\n",
                "    ),\n",
                ")\n",
                "\n",
                "plot.set_xticklabels([\"[0-10]\", \"(10-20]\", \"(20-30]\", \"(30-40]\", \"(40-50]\"])\n",
                "plot.set_xlabels(r\"Error Fraction ($\\%$)\")\n",
                "plot.set_ylabels(r\"Downstream Improvement ($\\%$)\")\n",
                "plot.set_titles(col_template=\"{col_name}\")\n",
                "\n",
                "plot.savefig(figures_path / \"confidence_set_size_performance_improvement_plot.pdf\", bbox_inches=\"tight\")\n",
                "plot.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.9.16 ('conformal-data-cleaning-JConAJEV-py3.9')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.18"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "4f5f6d5e11404dd34f5b1c6e5800578a48fa5a3d2b0a1598a851ff47c435ed59"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
