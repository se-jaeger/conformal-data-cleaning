{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ad0c0c-a618-4f8c-80c4-47af2f0d21bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from conformal_data_cleaning.evaluation.utils import (\n",
    "    calculate_median_percent_error_detection,\n",
    "    calculate_median_percent_error_wrong_detection,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1d0609-8b36-437f-a5e4-f7e631ea0c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_path = Path(\"../../processed\")\n",
    "results_file = processed_path / \"final-experiments\" / \"results_cache.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results: pd.DataFrame = (\n",
    "    pd.read_csv(results_file)\n",
    "    .convert_dtypes()\n",
    "    .query(\"cleaner_type == 'ConformalAutoGluon'\")\n",
    "    .copy()\n",
    "    .drop(columns=\"cleaner_type\")\n",
    "    .rename(columns={\"confidence_level\": \"hyperparameter\"})\n",
    ")\n",
    "baseline_garf_results: pd.DataFrame = (\n",
    "    pd.read_csv(results_file)\n",
    "    .convert_dtypes()\n",
    "    .query(\"cleaner_type == 'Garf'\")\n",
    "    .copy()\n",
    "    .drop(columns=\"cleaner_type\")\n",
    "    .rename(columns={\"confidence_level\": \"hyperparameter\"})\n",
    ")\n",
    "baseline_ml_results: pd.DataFrame = (\n",
    "    pd.read_csv(results_file)\n",
    "    .convert_dtypes()\n",
    "    .query(\"cleaner_type == 'AutoGluon'\")\n",
    "    .copy()\n",
    "    .drop(columns=\"cleaner_type\")\n",
    "    .rename(columns={\"confidence_level\": \"hyperparameter\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Detection True Positive Rate (TPR)\n",
    "\n",
    "Showing `median` values of all the experiments for a given model-hyperparameter-task combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_function = calculate_median_percent_error_detection\n",
    "\n",
    "\n",
    "median_percent_error_detection = pd.concat(\n",
    "    {\n",
    "        \"baseline_garf\": baseline_garf_results.groupby(\"task_id\").apply(\n",
    "            lambda x: x.groupby(\"hyperparameter\").apply(apply_function),\n",
    "        ),\n",
    "        \"baseline_ml\": baseline_ml_results.groupby(\"task_id\").apply(\n",
    "            lambda x: x.groupby(\"hyperparameter\").apply(apply_function),\n",
    "        ),\n",
    "        \"conformal_cleaning\": results.groupby(\"task_id\").apply(\n",
    "            lambda x: x.groupby(\"hyperparameter\").apply(apply_function),\n",
    "        ),\n",
    "    },\n",
    "    axis=\"columns\",\n",
    ").sort_values((\"conformal_cleaning\", 0.999))\n",
    "\n",
    "(median_percent_error_detection.style.background_gradient(cmap=\"RdYlGn\", vmin=50, vmax=100, axis=1).format(precision=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Detection - False Positive Rate (FPR)\n",
    "\n",
    "Showing `median` values of all the experiments for a given model-hyperparameter-task combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_function = calculate_median_percent_error_wrong_detection\n",
    "\n",
    "\n",
    "median_percent_error_wrong_detection = pd.concat(\n",
    "    {\n",
    "        \"baseline_garf\": baseline_garf_results.groupby(\"task_id\").apply(\n",
    "            lambda x: x.groupby(\"hyperparameter\").apply(apply_function),\n",
    "        ),\n",
    "        \"baseline_ml\": baseline_ml_results.groupby(\"task_id\").apply(\n",
    "            lambda x: x.groupby(\"hyperparameter\").apply(apply_function),\n",
    "        ),\n",
    "        \"conformal_cleaning\": results.groupby(\"task_id\").apply(\n",
    "            lambda x: x.groupby(\"hyperparameter\").apply(apply_function),\n",
    "        ),\n",
    "    },\n",
    "    axis=\"columns\",\n",
    ").sort_values((\"conformal_cleaning\", 0.999), ascending=False)\n",
    "(\n",
    "    median_percent_error_wrong_detection.style.background_gradient(cmap=\"RdYlGn_r\", vmin=0, vmax=20, axis=1).format(\n",
    "        precision=2,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pd.concat(\n",
    "        [\n",
    "            median_percent_error_detection.median(axis=0).to_frame(\"median_percent_error_detection\"),\n",
    "            median_percent_error_wrong_detection.median(axis=0).to_frame(\"median_percent_error_wrong_detection\"),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    .style.highlight_max(color=\"green\", axis=0, subset=\"median_percent_error_detection\")\n",
    "    .highlight_min(color=\"green\", axis=0, subset=\"median_percent_error_wrong_detection\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('conformal-data-cleaning-z_iY5k30-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1e079ba1052bcc85be9b78b3c72bf03a4d015549529e67f43de37f743ce1597"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
